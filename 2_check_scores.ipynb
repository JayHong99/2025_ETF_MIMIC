{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefbc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.metrics import log_loss, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f4152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "def softmax_by_sample(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "    \n",
    "\n",
    "def load_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def load_modality_output(seed, projection_dim, batch_size, modality, task) : \n",
    "    result_dir = Path(f'Results/Linear_{modality}/Seed_{seed}/{task}_proj_{projection_dim}_batch_{batch_size}')\n",
    "    output = load_pickle(result_dir / 'outputs' / 'best_epoch.pkl')\n",
    "    etf = Path(f'Results/ETF/ETF_{projection_dim}_IN_2_OUT_Seed_{seed}.pt')\n",
    "    etf = torch.load(etf)\n",
    "    return output, etf\n",
    "\n",
    "def load_fusion_ouptut(seed, projection_dim, batch_size, fusion_method, task) : \n",
    "    result_dir = Path(f'Results/Linear_MultiModal/Fusion_{fusion_method}/Seed_{seed}/{task}_proj_{projection_dim}_batch_{batch_size}')\n",
    "    output = load_pickle(result_dir / 'outputs' / 'best_epoch.pkl')    \n",
    "    return output\n",
    "\n",
    "def load_e2e_mm_output(seed, projection_dim, batch_size, fusion_method, task) : \n",
    "    result_dir = Path(f'Results/Linear_MultiModal/E2E_Fusion_{fusion_method}/Seed_{seed}/{task}_proj_{projection_dim}_batch_{batch_size}')\n",
    "    output = load_pickle(result_dir / 'outputs' / 'best_epoch.pkl')    \n",
    "    return output\n",
    "\n",
    "def unimodal_process(output, key):\n",
    "    data = output.get(key)\n",
    "    features = data['features']\n",
    "    return features\n",
    "\n",
    "def bimodal_process(output1, output2, key, weight1=0.5, weight2=0.5) : \n",
    "    data1 = output1.get(key)\n",
    "    data2 = output2.get(key)\n",
    "    features1 = data1['features']\n",
    "    features2 = data2['features']\n",
    "    # combined_features = (features1 + features2) / 2\n",
    "    combined_features = (features1 * weight1 + features2 * weight2) / (weight1 + weight2)\n",
    "    return features1, features2, combined_features\n",
    "\n",
    "def trimodal_process(output1, output2, output3, key, weight1=0.5, weight2=0.5, weight3=0.5) : \n",
    "    data1 = output1.get(key)\n",
    "    data2 = output2.get(key)\n",
    "    data3 = output3.get(key)\n",
    "    features1 = data1['features']\n",
    "    features2 = data2['features']\n",
    "    features3 = data3['features']\n",
    "    feature_12 = (features1 * weight1 + features2 * weight2) / (weight1 + weight2)\n",
    "    feature_13 = (features1 * weight1 + features3 * weight3) / (weight1 + weight3)\n",
    "    feature_23 = (features2 * weight2 + features3 * weight3) / (weight2 + weight3)\n",
    "    combined_features = (features1 * weight1 + features2 * weight2 + features3 * weight3) / (weight1 + weight2 + weight3)\n",
    "    return features1, features2, features3, feature_12, feature_13, feature_23, combined_features\n",
    "\n",
    "def whole_process(output1, output2, output3, key) : \n",
    "    data1 = output1.get(key, None)\n",
    "    data2 = output2.get(key, None)\n",
    "    data3 = output3.get(key, None)\n",
    "    # ignore none and agg the rest\n",
    "    features_list = [data['features'] for data in [data1, data2, data3] if data is not None]\n",
    "    features = np.mean(features_list, axis=0) if features_list else None\n",
    "    return features\n",
    "\n",
    "def get_output(modality, total_outputs, etf) : \n",
    "    labels, features = [], []\n",
    "    labels = [values['labels'] for values in total_outputs.values() if values[modality] is not None]\n",
    "    features = [[values[modality]] for values in total_outputs.values() if values[modality] is not None]\n",
    "    labels = np.array(labels)\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    probs = features @ etf.numpy()\n",
    "    probs = softmax(probs)\n",
    "    print(f\"{modality} - Features shape: {features.shape}, Probs shape: {probs.shape}, Labels shape: {labels.shape}\")\n",
    "    return labels, probs\n",
    "\n",
    "def get_performance(labels, probs):\n",
    "    roc_auc = roc_auc_score(labels, probs)\n",
    "    # pr_auc = average_precision_score(labels, probs)\n",
    "    precision, recall, _ = precision_recall_curve(labels, probs)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return roc_auc, pr_auc, len(labels)\n",
    "\n",
    "def get_score(modality, total_outputs, etf) : \n",
    "    labels, probs = get_output(modality, total_outputs, etf)\n",
    "    roc_auc, pr_auc, n = get_performance(labels, probs[:,1])\n",
    "    number_of_cases = (labels == 1).sum()\n",
    "    nll_loss = log_loss(labels, probs)\n",
    "    brier_loss = brier_score_loss(labels, probs[:,1])\n",
    "    return roc_auc, pr_auc, n, number_of_cases, nll_loss, brier_loss\n",
    "\n",
    "def get_fusion_score(fusion_method, total_outputs) : \n",
    "    labels, probs = [], []\n",
    "    labels = [values['labels'] for values in total_outputs.values()]\n",
    "    probs = [values[fusion_method + '_prob'] for values in total_outputs.values()]\n",
    "    labels = np.array(labels)\n",
    "    probs = np.stack(probs, axis=0)\n",
    "    print(f\"{fusion_method} - Probs shape: {probs.shape}, Labels shape: {labels.shape}\")\n",
    "    roc_auc, pr_auc, n = get_performance(labels, probs[:,1])\n",
    "    number_of_cases = (labels == 1).sum()\n",
    "    nll_loss = log_loss(labels, probs)\n",
    "    brier_loss = brier_score_loss(labels, probs[:,1])\n",
    "    return roc_auc, pr_auc, n, number_of_cases, nll_loss, brier_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75fb633",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_dim=128\n",
    "batch_size=512\n",
    "seed=2026\n",
    "task='mortality_90days'\n",
    "# task='readmission_15days'\n",
    "\n",
    "split_mode='test'\n",
    "\n",
    "\n",
    "total_scores = []\n",
    "for seed in range(2026, 2029) : \n",
    "\n",
    "    # Unimodal\n",
    "    tabular_outputs, proto = load_modality_output(seed, projection_dim, batch_size, 'tabular', task)\n",
    "    lab_outputs, _ = load_modality_output(seed, projection_dim, batch_size, 'lab', task)\n",
    "    note_outputs, _ = load_modality_output(seed, projection_dim, batch_size, 'note', task)\n",
    "    tab_output = tabular_outputs[split_mode]['outputs']\n",
    "    lab_output = lab_outputs[split_mode]['outputs']\n",
    "    note_output = note_outputs[split_mode]['outputs']\n",
    "    \n",
    "    # MM - FUSION / Extra Training\n",
    "    sum_outputs = load_fusion_ouptut(seed, projection_dim, batch_size, 'Sum', task)\n",
    "    weighted_sum_outputs = load_fusion_ouptut(seed, projection_dim, batch_size, 'WeightedFusion', task)\n",
    "    attn_masked_outputs = load_fusion_ouptut(seed, projection_dim, batch_size, 'AttnMaskedFusion', task)\n",
    "    sum_output = sum_outputs[split_mode]['outputs']\n",
    "    weighted_sum_output = weighted_sum_outputs[split_mode]['outputs']\n",
    "    attn_masked_output = attn_masked_outputs[split_mode]['outputs']\n",
    "    \n",
    "    # # E2E FUSION / End-to-end trainig\n",
    "    e2e_sum_outputs = load_e2e_mm_output(seed, projection_dim, batch_size, 'Sum', task)\n",
    "    e2e_sum_output = e2e_sum_outputs[split_mode]['outputs']\n",
    "    e2e_weighted_sum_outputs = load_e2e_mm_output(seed, projection_dim, batch_size, 'WeightedFusion', task)\n",
    "    e2e_weighted_sum_output = e2e_weighted_sum_outputs[split_mode]['outputs']\n",
    "    e2e_attn_masked_outputs = load_e2e_mm_output(seed, projection_dim, batch_size, 'AttnMaskedFusion', task)\n",
    "    e2e_attn_masked_output = e2e_attn_masked_outputs[split_mode]['outputs']\n",
    "    \n",
    "    ## PERFORMANCE EVALATION\n",
    "    split_mode = 'test'\n",
    "\n",
    "    tab_keys = set(tab_output.keys())\n",
    "    lab_keys = set(lab_output.keys())\n",
    "    note_keys = set(note_output.keys())\n",
    "\n",
    "    # 3개의 조합이면, 나올 수 있는 경우의 수\n",
    "    ## Tab > Lab & Tab > Note 포함관계\n",
    "    # 1.tab_total\n",
    "    tab_keys\n",
    "    # 2.lab_total\n",
    "    lab_keys\n",
    "    # 3.note_total\n",
    "    note_keys\n",
    "    # 4. tab - lab - note\n",
    "    tab_only_keys = tab_keys - lab_keys - note_keys\n",
    "    # 5. lab - note\n",
    "    lab_only_keys = lab_keys - note_keys\n",
    "    # 6. note - lab\n",
    "    note_only_keys = note_keys - lab_keys\n",
    "    # 7. lab ∩ note\n",
    "    lab_note_keys = lab_keys.intersection(note_keys)\n",
    "    # 8. total\n",
    "    total_keys = tab_keys.union(lab_keys).union(note_keys)\n",
    "\n",
    "    print(f\"1. tab total: {len(tab_keys)}\")\n",
    "    print(f\"2. lab total: {len(lab_keys)}\")\n",
    "    print(f\"3. note total: {len(note_keys)}\")\n",
    "    print(f\"4. tab only: {len(tab_only_keys)}\")\n",
    "    print(f\"5. lab only: {len(lab_only_keys)}\")\n",
    "    print(f\"6. note only: {len(note_only_keys)}\")\n",
    "    print(f\"7. lab & note: {len(lab_note_keys)}\")\n",
    "    print(f\"8. total: {len(total_keys)}\")\n",
    "\n",
    "    total_outputs = {}\n",
    "    for key in total_keys:\n",
    "        ### Unimodal feature extraction\n",
    "        # 1. tab total\n",
    "        tab_features = unimodal_process(tab_output, key) if key in tab_keys else None\n",
    "        # 2. lab total\n",
    "        lab_features = unimodal_process(lab_output, key) if key in lab_keys else None\n",
    "        # 3. note total\n",
    "        note_features = unimodal_process(note_output, key) if key in note_keys else None    \n",
    "        # 4. tab only\n",
    "        tab_only_features = unimodal_process(tab_output, key) if key in tab_only_keys else None\n",
    "        \n",
    "        ### Bimodal feature extraction\n",
    "        # 5. lab only : lab_only -> lab_only를 tab이 본 관점\n",
    "        lab_only_lab_features, lab_only_tab_features, lab_only_features = bimodal_process(lab_output, tab_output, key, weight1=0.5, weight2=0.5) if key in lab_only_keys else (None, None, None)\n",
    "        \n",
    "        # 6. note only : note_only -> note_only를 tab이 본 관점\n",
    "        note_only_note_features, note_only_tab_features, note_only_features = bimodal_process(note_output, tab_output, key, weight1=0.5, weight2=0.5) if key in note_only_keys else (None, None, None)\n",
    "        \n",
    "        ### Trimodal feature extraction\n",
    "        # 7. lab ∩ note\n",
    "        mm_tab_features, mm_lab_features, mm_note_features, mm_tab_lab_features, mm_tab_note_features, mm_lab_note_features, mm_all_features = trimodal_process(tab_output, lab_output, note_output, key, weight1=0.5, weight2=0.5, weight3=0.5) if key in lab_note_keys else (None, None, None, None, None, None, None)\n",
    "        \n",
    "        # 8. total\n",
    "        total_features = whole_process(tab_output, lab_output, note_output, key)\n",
    "        \n",
    "        # 9. Fusion - Sum\n",
    "        fusion_sum_prob = sum_output.get(int(key)).get('probs')\n",
    "        fusion_sum_prob = softmax_by_sample(fusion_sum_prob)\n",
    "        \n",
    "        # 10. Fusion - Weighted Sum\n",
    "        fusion_weighted_sum_prob = weighted_sum_output.get(int(key)).get('probs')\n",
    "        fusion_weighted_sum_prob = softmax_by_sample(fusion_weighted_sum_prob)\n",
    "        \n",
    "        # 11. Fusion - Attn Masked\n",
    "        fusion_attn_masked_prob = attn_masked_output.get(int(key)).get('probs')\n",
    "        fusion_attn_masked_prob = softmax_by_sample(fusion_attn_masked_prob)\n",
    "        \n",
    "        # # 12. E2E Fusion - Sum\n",
    "        e2e_fusion_sum_prob = e2e_sum_output.get(key).get('probs')\n",
    "        e2e_fusion_sum_prob = softmax_by_sample(e2e_fusion_sum_prob)\n",
    "        \n",
    "        # # 13. E2E Fusion - Weighted Sum\n",
    "        e2e_fusion_weighted_sum_prob = e2e_weighted_sum_output.get(key).get('probs')\n",
    "        e2e_fusion_weighted_sum_prob = softmax_by_sample(e2e_fusion_weighted_sum_prob)\n",
    "        \n",
    "        # # # 14. E2E Fusion - Attn Masked\n",
    "        e2e_fusion_attn_masked_prob = e2e_attn_masked_output.get(key).get('probs')\n",
    "        e2e_fusion_attn_masked_prob = softmax_by_sample(e2e_fusion_attn_masked_prob)\n",
    "        \n",
    "        # Label\n",
    "        label = tab_output.get(key)['labels']\n",
    "        \n",
    "        # Store results\n",
    "        total_outputs[key] = {\n",
    "            'tabular': tab_features,\n",
    "            'lab': lab_features,\n",
    "            'note': note_features,\n",
    "            'tab_only': tab_only_features,\n",
    "            'lab_only_lab': lab_only_lab_features, 'lab_only_tab': lab_only_tab_features, 'lab_only': lab_only_features,\n",
    "            'note_only_note': note_only_note_features, 'note_only_tab': note_only_tab_features, 'note_only': note_only_features,\n",
    "            'mm_tab': mm_tab_features, 'mm_lab': mm_lab_features, 'mm_note': mm_note_features,\n",
    "            'mm_tab_lab': mm_tab_lab_features, 'mm_tab_note': mm_tab_note_features, 'mm_lab_note': mm_lab_note_features,\n",
    "            'mm_all': mm_all_features,\n",
    "            'total': total_features,\n",
    "            'fusion_sum_prob': fusion_sum_prob,\n",
    "            'fusion_weighted_sum_prob': fusion_weighted_sum_prob,\n",
    "            'fusion_attn_masked_prob': fusion_attn_masked_prob,\n",
    "            'E2E_fusion_sum_prob' : e2e_fusion_sum_prob,\n",
    "            'E2E_fusion_weighted_sum_prob': e2e_fusion_weighted_sum_prob,\n",
    "            'E2E_fusion_attn_masked_prob': e2e_fusion_attn_masked_prob,\n",
    "            'labels' : label,\n",
    "        }\n",
    "    # Unimodal\n",
    "    total_scores.append([seed, 'Tabular', *get_score('tabular', total_outputs, proto)])\n",
    "    total_scores.append([seed, 'Lab', *get_score('lab', total_outputs, proto)])\n",
    "    total_scores.append([seed, 'Note', *get_score('note', total_outputs, proto)])\n",
    "    # Bimodal\n",
    "    total_scores.append([seed, 'Tab Only', *get_score('tab_only', total_outputs, proto)])\n",
    "    total_scores.append([seed, 'Lab Only', *get_score('lab_only', total_outputs, proto)])\n",
    "    total_scores.append([seed, 'Note Only', *get_score('note_only', total_outputs, proto)])\n",
    "    total_scores.append([seed, 'MM Tab', *get_score('mm_tab', total_outputs, proto)])\n",
    "    total_scores.append([seed, 'MM Lab', *get_score('mm_lab', total_outputs, proto)])\n",
    "    total_scores.append([seed, 'MM Note', *get_score('mm_note', total_outputs, proto)])\n",
    "    # Trimodal\n",
    "    total_scores.append([seed, 'MM Tab & Lab', *get_score('mm_tab_lab', total_outputs, proto)])\n",
    "    total_scores.append([seed, 'MM Tab & Note', *get_score('mm_tab_note', total_outputs, proto)])\n",
    "    total_scores.append([seed, 'MM Lab & Note', *get_score('mm_lab_note', total_outputs, proto)])\n",
    "    total_scores.append([seed, 'MM All', *get_score('mm_all', total_outputs, proto)])\n",
    "    # Total\n",
    "    total_scores.append([seed, 'Simple Average', *get_score('total', total_outputs, proto)])\n",
    "    total_scores.append([seed, 'Fusion - Sum', *get_fusion_score('fusion_sum', total_outputs)])\n",
    "    total_scores.append([seed, 'Fusion - Weighted Sum', *get_fusion_score('fusion_weighted_sum', total_outputs)])\n",
    "    total_scores.append([seed, 'Fusion - Attn Masked', *get_fusion_score('fusion_attn_masked', total_outputs)])\n",
    "    total_scores.append([seed, 'E2E Fusion - Sum', *get_fusion_score('E2E_fusion_sum', total_outputs)])\n",
    "    total_scores.append([seed, 'E2E Fusion - Weighted Sum', *get_fusion_score('E2E_fusion_weighted_sum', total_outputs)])\n",
    "    total_scores.append([seed, 'E2E Fusion - Attn Masked', *get_fusion_score('E2E_fusion_attn_masked', total_outputs)])\n",
    "\n",
    "total_score_df = pd.DataFrame(total_scores, columns=['Seed', 'Modality', 'ROC-AUC', 'PR-AUC', 'N', 'Number of Cases', 'NLL Loss', 'Brier Loss'])\n",
    "total_score_df_balanced = total_score_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf87caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_scores = total_score_df_balanced.groupby('Modality').mean().reset_index().drop(columns=['Seed'])\n",
    "avg_scores.columns = ['Modality', 'ROC-AUC', 'PR-AUC', 'N', 'Number of Cases', 'NLL Loss', 'Brier Loss']\n",
    "avg_scores[['N', 'Number of Cases']] = avg_scores[['N', 'Number of Cases']].astype(int)\n",
    "avg_scores[['Brier Loss', 'NLL Loss']] = avg_scores[['Brier Loss', 'NLL Loss']].apply(lambda x : round(x, 4))\n",
    "avg_scores['case_ratio'] = avg_scores['Number of Cases'] / avg_scores['N']\n",
    "# avg_scores = avg_scores.sort_values(by='ROC-AUC Mean', ascending=False),\n",
    "avg_scores = avg_scores[['Modality', 'Number of Cases', 'N', 'case_ratio', 'ROC-AUC', 'PR-AUC', 'Brier Loss', 'NLL Loss']]\n",
    "\n",
    "target_modality_and_order = [\n",
    "                            'Tabular', 'Lab', 'Note', # Unimodal\n",
    "                            'E2E Fusion - Sum',\n",
    "                            'E2E Fusion - Weighted Sum',\n",
    "                            'E2E Fusion - Attn Masked',\n",
    "                            # 'MM All', # Trimodal\n",
    "                            # 'Tab Only', 'Lab Only', 'Note Only', # Bimodal - only\n",
    "                            'Simple Average', # Total\n",
    "                            'Fusion - Sum', \n",
    "                            'Fusion - Weighted Sum', \n",
    "                            'Fusion - Attn Masked', # Fusion,\n",
    "                             ]\n",
    "avg_scores = avg_scores.set_index('Modality').loc[target_modality_and_order].reset_index()\n",
    "avg_scores[['ROC-AUC', 'PR-AUC']] = avg_scores[['ROC-AUC', 'PR-AUC']].apply(lambda x : round(x * 100, 2))\n",
    "avg_scores.to_csv(f'Results/Whole_{task.capitalize()}.csv', index=False)\n",
    "avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg\n",
    "avg_scores = total_score_df_balanced.groupby('Modality').mean().reset_index().drop(columns=['Seed'])\n",
    "avg_scores.columns = ['Modality', 'ROC-AUC', 'PR-AUC', 'N', 'Number of Cases', 'NLL Loss', 'Brier Loss']\n",
    "\n",
    "target_modality_and_order = ['MM Tab', 'MM Lab', 'MM Note', # Bimodal - cross\n",
    "                             'MM Tab & Lab', 'MM Tab & Note', 'MM Lab & Note', # Trimodal - pair\n",
    "                             'MM All', # Trimodal - all\n",
    "                             ]\n",
    "avg_scores = avg_scores.set_index('Modality').loc[target_modality_and_order].reset_index()\n",
    "avg_scores['AVG'] = avg_scores[['ROC-AUC', 'PR-AUC']].mean(axis=1)\n",
    "avg_scores[['ROC-AUC', 'PR-AUC', 'AVG']] = avg_scores[['ROC-AUC', 'PR-AUC', 'AVG']].apply(lambda x : round(x * 100, 2))\n",
    "avg_scores[['NLL Loss', 'Brier Loss']] = avg_scores[['NLL Loss', 'Brier Loss']].apply(lambda x : round(x,4))\n",
    "avg_scores = avg_scores[['Modality', 'ROC-AUC', 'PR-AUC', 'AVG', 'NLL Loss', 'Brier Loss']]\n",
    "avg_scores.to_csv(f'Results/MM_{task.capitalize()}.csv', index=False)\n",
    "avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc760d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg\n",
    "avg_scores = total_score_df_balanced.groupby('Modality').mean().reset_index().drop(columns=['Seed'])\n",
    "avg_scores.columns = ['Modality', 'ROC-AUC', 'PR-AUC', 'N', 'Number of Cases', 'NLL Loss', 'Brier Loss']\n",
    "\n",
    "target_modality_and_order = ['Tabular', 'Lab', 'Note', # Unimodal\n",
    "                             'Tab Only', 'Lab Only', 'Note Only', # Unimodal - no intersection\n",
    "                             ]\n",
    "avg_scores = avg_scores.set_index('Modality').loc[target_modality_and_order].reset_index()\n",
    "avg_scores['AVG'] = avg_scores[['ROC-AUC', 'PR-AUC']].mean(axis=1)\n",
    "avg_scores[['ROC-AUC', 'PR-AUC', 'AVG']] = avg_scores[['ROC-AUC', 'PR-AUC', 'AVG']].apply(lambda x : round(x * 100, 2))\n",
    "avg_scores[['NLL Loss', 'Brier Loss']] = avg_scores[['NLL Loss', 'Brier Loss']].apply(lambda x : round(x,4))\n",
    "avg_scores = avg_scores[['Modality', 'ROC-AUC', 'PR-AUC', 'AVG', 'NLL Loss', 'Brier Loss']]\n",
    "avg_scores.to_csv(f'Results/Whole_{task.capitalize()}.csv', index=False)\n",
    "avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee8f45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d5ab9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547c812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e20123",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 'admission_ids_seed_2026.pkl'\n",
    "sample = pickle.load(open(Path('/home/data/2025_MIMICIV_processed/mimic4/task:mortality_90days') / sample, 'rb'))\n",
    "label = pickle.load(open(Path('/home/data/2025_MIMICIV_processed/mimic4/task:mortality_90days') / 'admission_ids_seed_2026_noise_0.01.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58135f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_code_ids = sample['train_code_ids']\n",
    "train_lab_ids = sample['train_lab_ids']\n",
    "train_note_ids = sample['train_discharge_ids']\n",
    "\n",
    "valid_code_ids = sample['val_code_ids']\n",
    "valid_lab_ids = sample['val_lab_ids']\n",
    "valid_note_ids = sample['val_discharge_ids']\n",
    "\n",
    "test_code_ids = sample['test_code_ids']\n",
    "test_lab_ids = sample['test_lab_ids']\n",
    "test_note_ids = sample['test_discharge_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a574892",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_code_labels = label['train_code_ids']\n",
    "train_lab_labels = label['train_lab_ids']\n",
    "train_note_labels = label['train_discharge_ids']\n",
    "valid_code_labels = label['val_code_ids']\n",
    "valid_lab_labels = label['val_lab_ids']\n",
    "valid_note_labels = label['val_discharge_ids']\n",
    "test_code_labels = label['test_code_ids']\n",
    "test_lab_labels = label['test_lab_ids']\n",
    "test_note_labels = label['test_discharge_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184301bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_ids = train_code_ids + valid_code_ids + test_code_ids\n",
    "lab_ids = train_lab_ids + valid_lab_ids + test_lab_ids\n",
    "note_ids = train_note_ids + valid_note_ids + test_note_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8fedbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_dict = pickle.load(open(Path('/home/data/2025_MIMICIV_processed/mimic4/hosp_adm_dict_90days.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d527b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_dict['23196014'].mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45861552",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {key : admission_dict[key].mortality for key in np.array(list(admission_dict.keys()))}\n",
    "new_dict = {key : value for key, value in new_dict.items() if value is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c6bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabular -> code_ids\n",
    "# Time -> lab_ids\n",
    "# Note -> note_ids\n",
    "\n",
    "# Tabular only -> code_ids - lab_ids - note_ids\n",
    "# Lab only -> lab_ids - note_ids\n",
    "# Note only -> note_ids - lab_ids\n",
    "# Multi -> code_ids ∩ lab_ids ∩ note_ids\n",
    "\n",
    "# get sample size, label size, positive ratio for each modality\n",
    "tabular = {key : new_dict[key] for key in code_ids}\n",
    "lab = {key : new_dict[key] for key in lab_ids}\n",
    "note = {key : new_dict[key] for key in note_ids}    \n",
    "tabular_only = {key : new_dict[key] for key in set(code_ids) - set(lab_ids) - set(note_ids)}\n",
    "lab_only = {key : new_dict[key] for key in set(lab_ids) - set(note_ids)}\n",
    "note_only = {key : new_dict[key] for key in set(note_ids) - set(lab_ids)}\n",
    "multimodal = {key : new_dict[key] for key in set(code_ids).intersection(set(lab_ids)).intersection(set(note_ids))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7fca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dfs= [] \n",
    "for name, dist_dict in [\n",
    "    ['Tabular', tabular],\n",
    "    ['Lab', lab],\n",
    "    ['Note', note],\n",
    "    ['Tabular Only', tabular_only],\n",
    "    ['Lab Only', lab_only],\n",
    "    ['Note Only', note_only],\n",
    "    ['Multimodal', multimodal]\n",
    "] : \n",
    "    print(f\"{name} - Sample Size: {len(dist_dict)}, Positive Cases: {sum(dist_dict.values())}, Positive Ratio: {sum(dist_dict.values()) / len(dist_dict):.4f}\")\n",
    "    new_dfs.append(pd.DataFrame({\n",
    "        'Modality' : name,\n",
    "        'Positive Cases' : sum(dist_dict.values()),\n",
    "        'Sample Size' : len(dist_dict),\n",
    "        'Positive Ratio' : round(sum(dist_dict.values()) / len(dist_dict), 4) * 100\n",
    "    }, index=[0]))  \n",
    "final_df = pd.concat(new_dfs, axis=0).reset_index(drop=True)\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Robust Venv",
   "language": "python",
   "name": "robust_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
